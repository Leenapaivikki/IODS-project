---
title: "Introduction to Open Data Science: Rstudio Exercise2"
author: "leenapaivikki"
output: html_document
---


```{r start, echo=FALSE, message=FALSE}
#Packages required in this exercise.
library(dplyr)
library(GGally)
library(ggplot2)
```
#Analysis of the Learning Data

#Description of data

The data of the analysis derives from the survey "Learning Approaches and Students' Achievements" in an Introductory Statistics Course in Finland in 2014. The target of the study is to measure the relationship between the  students' learning approaches and their achievements.

There are 183 observations and 60 variables. Most of the questions are learning related questions, the answers are given on Likert scale from 1 to 5. Some background variables (age, attitude to statistics, points) are included as well. The learning approaches variables - deep learning, surface learning and strategic learning - are created by combing questions that can be thought to measure the same dimension. The combination variables are averaged.</p>

#Load of data
```{r read_data}
learning2014v2 <- as.data.frame(read.table('learning2014.csv', sep="\t", header=TRUE))
```

#Explore the structure of the dataframe
```{r structure_data}
str(learning2014v2)
```
#Explore the dimension of the dataframe</code>
```{r dimension_data}
dim(learning2014v2)
```
#Show a graphical overview of the data and show summaries of the variables in the data.
If there are a handul of variables, it is possible to visulize The relationships between the variables in a single plot. A scatter plot matrix can be drawn by using function ggpairs and coloured by the gender variable.

```{r scatter_plot_matrice}
p <- ggpairs(learning2014v2, mapping = aes(col=gender), lower = list(combo = wrap("facethist", bins = 20)))
p
```

#A summary of each of the variables
```{r data_summary}
summary(learning2014v2)
```
#Description and interpretation of the outputs
The graphical overview and the summary of the data showcase the large range of variables. The distribution of the variables is quite wide. The target of this analysis is to clarify the relationship of the student's learning approaches and the results achieved. The correlations between variables are rather weak in all cases. The attitude variable is exception, it correlates strongly with the points variable. The age distribution shows that most students are at their twenties as could be assumed. The gender distribution is skewed, significantly more female students attended the course than male.  The distributions of attitude, deep, stra and surf variables follow rather close to normal distribution. The points distribution is skewed, the distribution demonstrates that the student achieved good results.

#Regression model fitting
A linear regression model can be fit using lm function
The explanatory variables are attitude, deep and stra.
```{r lm}
learning2014v2_model <- lm(points ~ attitude + deep + stra, data = learning2014v2)
```
```{r lm_model}
summary(learning2014v2_model)
```
The dependent variable is points and the explanatory variables are attitude, deep and stra.

The model is found by minimizing the sum of squared residuals. First there is a five point summary of residuals of the model. The coefficients give the estimates of the parameters of the model. Intercept relates to parameters of output variable.

The estimation describes the effect of an explanatory variable on the output variable. P value of the statistical test is very low in case attitude so we can conclude that there is statistical relationship between attitude and points. The P test values of deep and  stra are much higher and indicates that the variables don't have strong relationship with output variable. The deep variable has lowest correlation with points, so it can be excluded from the further analysis.

The explanatory variables in the next fitted test are attitude and stra.
```{r lm_final}
learning2014v2_model <- lm(points ~ attitude + stra, data = learning2014v2)
```
```{r lm_model_final}
summary(learning2014v2_model)
```

#Final analysis
The fitted model was created by removing one explanatory variable, the deep variable, which have weak correlation with the output variable and the other variables. Based on the summary of the fitted model it can be concluded that the deep variable doesn't have much impact on the model. The statistical significance of the model is rather good. The p-value is low.
The model as a whole is not good, because the Multiple R-squarded value is only 0.20 which implies that only 20% of the relationship between the output value points and the explanatory variables can be explain with this model. Thus 80% on the relationship remains unexplained.


## Diagnostic plots and assumptions and their validity of the model

There are three assumptions of linear regression models: the errors are normally distributed, they are not correlated and have constant variance.
QQ-plot of the residuals provides a method to explore the assumption that the errors are normally distributed. The constant variance assumption implies that the size of the errors should not depend on the explanatory variables and it can be explored with a simple scatter plot of residuals versus model predictions. Any pattern in the scatter plot implies a problem with the assumptions.

The next diagnostic plots are produced: Residuals vs Fitted values, Normal QQ-plot, Residuals vs Leverage.

```{r diag_plots, fig.width=10, fig.height=4}
par(mfrow = c(1,3))
# Draw diagnostic plots using the plot() function. Choose the plots 1, 2 and 5
plot(learning2014v2_model, which = c(1,2,5))
```

#Interpretation of the plots:

The Residuals vs Fitted plot doesn't show any kind of pattern and the values are randomly distributed. Based on that, it can be concluded that the errors are not correlated with the explanatory variables and their size is not dependent on the explanatory variables.

The Normal Q-Q-plot Residuals diagnostic plot showcases that the model fits to the theoretical model rather well. The better the points are within the line, the better the model fits to the normality assumption.

Leverage of observations measures, how much impact a single observation has on the model. Residuals vs Leverage plot helps to identify which observations have an unusually high impact. The single outliner can have high impact on the model. In this case there is no outliner in the plot and the result of the diagnostic is regular leverage.  

